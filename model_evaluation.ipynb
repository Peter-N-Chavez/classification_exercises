{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "from pydataset import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from acquire import *\n",
    "from prepare import *\n",
    "from explore import *\n",
    "import env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|               | pred dog   | pred cat   |\n",
    "|:------------  |-----------:|-----------:|\n",
    "| actual dog    |         46 |         7  |\n",
    "| actual cat    |         13 |         34 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this evaluation, I am choosing \"dog\" to be the positive/affirmitive.\n",
    "\n",
    "# A false positive would be that the prediction was dog, but it was actually a cat.\n",
    "\n",
    "# A false negative would be that the prediction was cat, but it was actually a dog.\n",
    "\n",
    "#True positive is predicting its a dog, and it's a dog.\n",
    "tp = 46\n",
    "\n",
    "#True negative is predicting its a cat, and it's a cat.\n",
    "tn = 34\n",
    "\n",
    "#False positive is predicting its a dog, but it's a cat.\n",
    "fp = 13\n",
    "\n",
    "#false negative is predicting its a cat, but it's a dog.\n",
    "fn = 7\n",
    "\n",
    "print(\"Dog-classifier (where 'dog' is the positive prediction)\")\n",
    "\n",
    "print(\"True Positives\", tp)\n",
    "print(\"False Positives\", fp)\n",
    "print(\"False Negatives\", fn)\n",
    "print(\"True Negatives\", tn)\n",
    "\n",
    "print(\"-------------\")\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(\"Accuracy is\", accuracy)\n",
    "print(\"Recall is\", round(recall,2))\n",
    "print(\"Precision is\", round(precision,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_tit(pd.DataFrame(new_tit_df()))\n",
    "\n",
    "train, validate, test = prep_split(df, \"survived\")\n",
    "train = train.drop(columns = [\"sex\", \"embark_town\"])\n",
    "validate = validate.drop(columns = [\"sex\", \"embark_town\"])\n",
    "test = test.drop(columns = [\"sex\", \"embark_town\"])\n",
    "\n",
    "baseline = y_train.mode()\n",
    "\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline prediction: {baseline[0]}\")\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")\n",
    "\n",
    "num_type_list, cat_type_list = dtypes_to_list(train)\n",
    "cat_analysis(train, \"survived\", cat_type_list)\n",
    "\n",
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 50):\n",
    "    \n",
    "    depth = 6\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df\n",
    "\n",
    "df.set_index('min_samples_per_leaf')[['train_accuracy', 'validate_accuracy', 'difference']].plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,50,5))\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data('iris')\n",
    "\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "train, test = train_test_split(df, \n",
    "                               stratify=df['species'], \n",
    "                               train_size=0.8, \n",
    "                               random_state=1349)\n",
    "train, validate = train_test_split(train, \n",
    "                                   stratify=train['species'], \n",
    "                                   train_size=0.7, \n",
    "                                   random_state=1349)\n",
    "\n",
    "X_train = train.drop(columns=['species', 'petal_length', 'petal_width'])\n",
    "y_train = train.species\n",
    "\n",
    "X_validate = validate.drop(columns=['species', 'petal_length', 'petal_width'])\n",
    "y_validate = validate.species\n",
    "\n",
    "X_test = test.drop(columns=['species', 'petal_length', 'petal_width'])\n",
    "y_test = test.species\n",
    "\n",
    "sns.scatterplot(data=train, x='sepal_length', y='sepal_width', hue='species');\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "model_set = []\n",
    "model_accuracies = {}\n",
    "for i in range(1,10):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_set.append(clf)\n",
    "    model_accuracies[f'{i}_neighbors'] = {\n",
    "        'train_score': round(clf.score(X_train, y_train), 2),\n",
    "        'validate_score': round(clf.score(X_validate, y_validate), 2)}\n",
    "\n",
    "model_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.5250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>772</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  passenger_id  survived  pclass   age  sibsp  parch     fare  \\\n",
       "456         456           456         0       1  65.0      0      0  26.5500   \n",
       "150         150           150         0       2  51.0      0      0  12.5250   \n",
       "772         772           772         0       2  57.0      0      0  10.5000   \n",
       "125         125           125         1       3  12.0      1      0  11.2417   \n",
       "688         688           688         0       3  18.0      0      0   7.7958   \n",
       "\n",
       "     embark_town  alone  sex_male  embark_town_Queenstown  \\\n",
       "456  Southampton      1         1                       0   \n",
       "150  Southampton      1         1                       0   \n",
       "772  Southampton      1         0                       0   \n",
       "125    Cherbourg      0         1                       0   \n",
       "688  Southampton      1         1                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "456                        1  \n",
       "150                        1  \n",
       "772                        1  \n",
       "125                        0  \n",
       "688                        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Logistic Regression ['age', 'pclass', 'fare'] features.\n",
      "Accuracy of Logistic Regression classifier on training set: 0.71\n",
      "\n",
      "Logistic Regression ['age', 'fare', 'pclass', 'sex_male'] features.\n",
      "Accuracy of Logistic Regression classifier on training set: 0.82\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78       110\n",
      "           1       0.65      0.63      0.64        68\n",
      "\n",
      "    accuracy                           0.73       178\n",
      "   macro avg       0.71      0.71      0.71       178\n",
      "weighted avg       0.73      0.73      0.73       178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tolerance</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.593633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.734082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.807116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.810861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.805243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.790262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.762172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.698502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tolerance  accuracy\n",
       "0        0.0  0.383895\n",
       "1        0.1  0.593633\n",
       "2        0.2  0.734082\n",
       "3        0.3  0.807116\n",
       "4        0.4  0.810861\n",
       "5        0.5  0.816479\n",
       "6        0.6  0.805243\n",
       "7        0.7  0.790262\n",
       "8        0.8  0.762172\n",
       "9        0.9  0.698502"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_titanic_data()\n",
    "df = prep_tit(df)\n",
    "train, validate, test = prep_split(df, \"survived\")\n",
    "\n",
    "impute_col_nan(train, \"age\", \"median\")\n",
    "impute_col_nan(validate, \"age\", \"median\")\n",
    "impute_col_nan(test, \"age\", \"median\")\n",
    "\n",
    "display(train.head())\n",
    "\n",
    "X_train, y_train = train.drop(columns='survived'), train.survived\n",
    "X_validate, y_validate = validate.drop(columns='survived'), validate.survived\n",
    "X_test, y_test = test.drop(columns='survived'), test.survived\n",
    "\n",
    "dropcols = ['embark_town']\n",
    "X_train = X_train.drop(columns=['embark_town'])\n",
    "X_validate, X_test = X_validate.drop(columns=dropcols), X_test.drop(columns=dropcols)\n",
    "\n",
    "baseline_accuracy = round((train.survived == 0).mean(), 2)\n",
    "\n",
    "logit = LogisticRegression(random_state=1349)\n",
    "selected_feats = ['age', 'pclass', 'fare']\n",
    "logit.fit(X_train[selected_feats], y_train)\n",
    "y_pred = logit.predict(X_train[selected_feats])\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression\", selected_feats, \"features.\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[selected_feats], y_train)))\n",
    "print()\n",
    "\n",
    "logit1 = LogisticRegression(random_state=1349)\n",
    "features = ['age', 'fare', 'pclass', 'sex_male']\n",
    "logit1.fit(X_train[features], y_train)\n",
    "y_pred = logit1.predict(X_train[features])\n",
    "\n",
    "print(\"Logistic Regression\", features, \"features.\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit1.score(X_train[features], y_train)))\n",
    "print()\n",
    "\n",
    "y_pred = logit1.predict(X_validate[features])\n",
    "\n",
    "print(classification_report(y_validate, y_pred))\n",
    "\n",
    "y_pred_proba = logit1.predict_proba(X_train[features])\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba, columns = ['not-survived', 'survived'])\n",
    "y_pred_proba.head()\n",
    "\n",
    "tolerance, model_scores = [], []\n",
    "\n",
    "for i in np.arange(0,1,.1):\n",
    "    y_pred = (y_pred_proba.survived > i).astype(int)\n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    model_scores.append(accuracy)\n",
    "    tolerance.append(i.round(1))\n",
    "\n",
    "scores = {\"tolerance\":tolerance, \"accuracy\":model_scores}\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "display(df)\n",
    "\n",
    "graph = sns.lineplot(data = df, x = \"tolerance\", y = \"accuracy\")\n",
    "graph.set_xlim(0, 1)\n",
    "graph.set_ylim(0, 1)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
