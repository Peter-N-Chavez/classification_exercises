{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "from pydataset import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from acquire import *\n",
    "from prepare import *\n",
    "from explore import *\n",
    "import env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|               | pred dog   | pred cat   |\n",
    "|:------------  |-----------:|-----------:|\n",
    "| actual dog    |         46 |         7  |\n",
    "| actual cat    |         13 |         34 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this evaluation, I am choosing \"dog\" to be the positive/affirmitive.\n",
    "\n",
    "# A false positive would be that the prediction was dog, but it was actually a cat.\n",
    "\n",
    "# A false negative would be that the prediction was cat, but it was actually a dog.\n",
    "\n",
    "#True positive is predicting its a dog, and it's a dog.\n",
    "tp = 46\n",
    "\n",
    "#True negative is predicting its a cat, and it's a cat.\n",
    "tn = 34\n",
    "\n",
    "#False positive is predicting its a dog, but it's a cat.\n",
    "fp = 13\n",
    "\n",
    "#false negative is predicting its a cat, but it's a dog.\n",
    "fn = 7\n",
    "\n",
    "print(\"Dog-classifier (where 'dog' is the positive prediction)\")\n",
    "\n",
    "print(\"True Positives\", tp)\n",
    "print(\"False Positives\", fp)\n",
    "print(\"False Negatives\", fn)\n",
    "print(\"True Negatives\", tn)\n",
    "\n",
    "print(\"-------------\")\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(\"Accuracy is\", accuracy)\n",
    "print(\"Recall is\", round(recall,2))\n",
    "print(\"Precision is\", round(precision,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_tit(pd.DataFrame(new_tit_df()))\n",
    "\n",
    "train, validate, test = prep_split(df, \"survived\")\n",
    "train = train.drop(columns = [\"sex\", \"embark_town\"])\n",
    "validate = validate.drop(columns = [\"sex\", \"embark_town\"])\n",
    "test = test.drop(columns = [\"sex\", \"embark_town\"])\n",
    "\n",
    "baseline = y_train.mode()\n",
    "\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline prediction: {baseline[0]}\")\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")\n",
    "\n",
    "num_type_list, cat_type_list = dtypes_to_list(train)\n",
    "cat_analysis(train, \"survived\", cat_type_list)\n",
    "\n",
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 50):\n",
    "    \n",
    "    depth = 6\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df\n",
    "\n",
    "df.set_index('min_samples_per_leaf')[['train_accuracy', 'validate_accuracy', 'difference']].plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,50,5))\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data('iris')\n",
    "\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "train, test = train_test_split(df, \n",
    "                               stratify=df['species'], \n",
    "                               train_size=0.8, \n",
    "                               random_state=1349)\n",
    "train, validate = train_test_split(train, \n",
    "                                   stratify=train['species'], \n",
    "                                   train_size=0.7, \n",
    "                                   random_state=1349)\n",
    "\n",
    "X_train = train.drop(columns=['species', 'petal_length', 'petal_width'])\n",
    "y_train = train.species\n",
    "\n",
    "X_validate = validate.drop(columns=['species', 'petal_length', 'petal_width'])\n",
    "y_validate = validate.species\n",
    "\n",
    "X_test = test.drop(columns=['species', 'petal_length', 'petal_width'])\n",
    "y_test = test.species\n",
    "\n",
    "sns.scatterplot(data=train, x='sepal_length', y='sepal_width', hue='species');\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "model_set = []\n",
    "model_accuracies = {}\n",
    "for i in range(1,10):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_set.append(clf)\n",
    "    model_accuracies[f'{i}_neighbors'] = {\n",
    "        'train_score': round(clf.score(X_train, y_train), 2),\n",
    "        'validate_score': round(clf.score(X_validate, y_validate), 2)}\n",
    "\n",
    "model_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.5250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>772</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  passenger_id  survived  pclass   age  sibsp  parch     fare  \\\n",
       "456         456           456         0       1  65.0      0      0  26.5500   \n",
       "150         150           150         0       2  51.0      0      0  12.5250   \n",
       "772         772           772         0       2  57.0      0      0  10.5000   \n",
       "125         125           125         1       3  12.0      1      0  11.2417   \n",
       "688         688           688         0       3  18.0      0      0   7.7958   \n",
       "\n",
       "     embark_town  alone  sex_male  embark_town_Queenstown  \\\n",
       "456  Southampton      1         1                       0   \n",
       "150  Southampton      1         1                       0   \n",
       "772  Southampton      1         0                       0   \n",
       "125    Cherbourg      0         1                       0   \n",
       "688  Southampton      1         1                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "456                        1  \n",
       "150                        1  \n",
       "772                        1  \n",
       "125                        0  \n",
       "688                        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Logistic Regression ['age', 'pclass', 'fare'] features.\n",
      "Accuracy of Logistic Regression classifier on training set: 0.71\n",
      "\n",
      "Logistic Regression ['age', 'fare', 'pclass', 'sex_male'] features.\n",
      "Accuracy of Logistic Regression classifier on training set: 0.82\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78       110\n",
      "           1       0.65      0.63      0.64        68\n",
      "\n",
      "    accuracy                           0.73       178\n",
      "   macro avg       0.71      0.71      0.71       178\n",
      "weighted avg       0.73      0.73      0.73       178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'threshold 0.0': 0.3838951310861423,\n",
       " 'threshold 0.1': 0.5936329588014981,\n",
       " 'threshold 0.2': 0.7340823970037453,\n",
       " 'threshold 0.30000000000000004': 0.8071161048689138,\n",
       " 'threshold 0.4': 0.8108614232209738,\n",
       " 'threshold 0.5': 0.8164794007490637,\n",
       " 'threshold 0.6000000000000001': 0.8052434456928839,\n",
       " 'threshold 0.7000000000000001': 0.7902621722846442,\n",
       " 'threshold 0.8': 0.7621722846441947,\n",
       " 'threshold 0.9': 0.6985018726591761}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_titanic_data()\n",
    "df = prep_tit(df)\n",
    "train, validate, test = prep_split(df, \"survived\")\n",
    "\n",
    "impute_col_nan(train, \"age\", \"median\")\n",
    "impute_col_nan(validate, \"age\", \"median\")\n",
    "impute_col_nan(test, \"age\", \"median\")\n",
    "\n",
    "display(train.head())\n",
    "\n",
    "X_train, y_train = train.drop(columns='survived'), train.survived\n",
    "X_validate, y_validate = validate.drop(columns='survived'), validate.survived\n",
    "X_test, y_test = test.drop(columns='survived'), test.survived\n",
    "\n",
    "dropcols = ['embark_town']\n",
    "X_train = X_train.drop(columns=['embark_town'])\n",
    "X_validate, X_test = X_validate.drop(columns=dropcols), X_test.drop(columns=dropcols)\n",
    "\n",
    "baseline_accuracy = round((train.survived == 0).mean(), 2)\n",
    "\n",
    "logit = LogisticRegression(random_state=1349)\n",
    "selected_feats = ['age', 'pclass', 'fare']\n",
    "logit.fit(X_train[selected_feats], y_train)\n",
    "y_pred = logit.predict(X_train[selected_feats])\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression\", selected_feats, \"features.\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[selected_feats], y_train)))\n",
    "print()\n",
    "\n",
    "logit1 = LogisticRegression(random_state=1349)\n",
    "features = ['age', 'fare', 'pclass', 'sex_male']\n",
    "logit1.fit(X_train[features], y_train)\n",
    "y_pred = logit1.predict(X_train[features])\n",
    "\n",
    "print(\"Logistic Regression\", features, \"features.\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit1.score(X_train[features], y_train)))\n",
    "print()\n",
    "\n",
    "y_pred = logit1.predict(X_validate[features])\n",
    "\n",
    "print(classification_report(y_validate, y_pred))\n",
    "\n",
    "y_pred_proba = logit1.predict_proba(X_train[features])\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba, columns = ['not-survived', 'survived'])\n",
    "y_pred_proba.head()\n",
    "\n",
    "model_scores = {}\n",
    "for i in np.arange(0,1,.1):\n",
    "    y_pred = (y_pred_proba.survived > i).astype(int)\n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    model_scores[f'threshold {i}'] =  accuracy\n",
    "\n",
    "display(model_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
